---
title: "R Project - Regression"
subtitle: "4375 Machine Learning with Dr. Mazidi"
author: "Hamna Mustafa"
date: "10/17/2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

# Reading in the data

I found this dataset from https://www.kaggle.com/bluehorseshoe/uk-2016-road-safety-data/data?select=Cas.csv 
This contains data about vehicle accidents in the UK in 2016. The data that I needed was in two different csv files so the first thing I did was read them in and merge them. I merged them using the Accident Index because that was the common column between the two files. 


```{r}
df1 <- read.csv("/Users/hmnmustafa/Downloads/Cas.csv")
df2 <- read.csv("/Users/hmnmustafa/Downloads/dftRoadSafety_Accidents_2016.csv")
df <- merge(df1,df2,by=c('Accident_Index'),all.x=T)
```

# Data exploration and cleaning the data

The data had 47 columns and looking at them, I realized that many of these columns are unnecessary for my project. My target value of the Number of Casualties. I want to see if I can predict the Number of Casualties in an accident using the data provided. Hence, I cleaned up the data so it only included the columns that I was interested in. 

Then, I check to see if there are any NAs. The Latitude and Longitude had 11 NAs. That wasn't too many so I decided that replacing them with the Median of the attribute would be a good idea. 

Next, I used str to see what the dataset looks like now that I have cleaned it up a bit. I noticed that the Speed Limit was in chr instead of num. I need it to be a number in order to use it as a predictor so I convert it into a num. I check for NAs one more time and handle them. 


```{r}
str(df)
df <- df[,c(5,6,8,11,12,19,20,22,23,24,33,40,41,42)]

sapply(df, function(x) sum(is.na(x)==TRUE))


df$Longitude[is.na(df$Longitude)] <- median(df$Longitude,na.rm=T)
df$Latitude[is.na(df$Latitude)] <- median(df$Latitude,na.rm=T)

sapply(df, function(x) sum(is.na(x)==TRUE))

str(df)

df$Speed_limit <- as.numeric(df$Speed_limit)

sapply(df, function(x) sum(is.na(x)==TRUE))
df$Speed_limit[is.na(df$Speed_limit)] <- median(df$Speed_limit,na.rm=T)
sapply(df, function(x) sum(is.na(x)==TRUE))
```

Upon further exploration, we gain some more knowledge about this dataset. Since Number of Casualities is our target variable, we can compute the correlation between the target variable and all other variables. Looking at the correlations, we can see that the only Car_Passenger, Bus_or_Coach_Passenger and Number_of_Vehicles have a very slight correlation with Number of Casuatlies so we will plot those. 

My last step is to check if there is any attribute that needs to be converted into a factor. From the looks of it, Casualty Severity and Accident Severity should be a factor with 3 classes. Sex of casualty should also be a factor with 2 classes. Finally, it looks like Light conditions, weather conditions and Road Surface conditions are also divided into classes with different levels. Thus, I converted all of these into factors.

```{r}

str(df)
names(df)
dim(df)
summary(df)
head(df)

cor(df, df$Number_of_Casualties)

plot(df$Car_Passenger, df$Number_of_Casualties)
plot(df$Bus_or_Coach_Passenger, df$Number_of_Casualties)
plot(df$Number_of_Vehicles, df$Number_of_Casualties)

df$Sex_of_Casualty <- factor(df$Sex_of_Casualty)
df$Casualty_Severity <- factor(df$Casualty_Severity)
df$Accident_Severity <- factor(df$Accident_Severity)
df$Light_Conditions <- factor(df$Light_Conditions)
df$Weather_Conditions <- factor(df$Weather_Conditions)
df$Road_Surface_Conditions <- factor(df$Road_Surface_Conditions)

str(df)
```

# Dividing into test and train sets

```{r}

set.seed(1234)
i <- sample(1:nrow(df), nrow(df)*0.75,replace=FALSE)
train <- df[i,]
test <- df[-i,]

```

# Linear Regression

I am creating one model that uses all the predictors and one model that only uses Car_Passenger, Bus_or_Coach_Passenger and Number_of_Vehicles as the predictors.
The R-squared values are 0.2433 and 0.1786 respectively for models 1 and 2. This suggests that model 1 is a better model. The F-statistics are 1366 vs 9860 respectively with very low p-values for both. This suggests that model 2 is a better model as it has a higher F-statistic. 
Finally, once we test both models, we get a correlation of 0.4976 for model 1 and 0.426 for model 2. Furthermore, the Mean squared error of model 1 was also lower. This shows that although both models are pretty similar, model 1 performed better.


```{r}
lm1 <- lm(Number_of_Casualties~., data=train)
summary(lm1)

lm2 <- lm(Number_of_Casualties~Car_Passenger+Bus_or_Coach_Passenger+Number_of_Vehicles, data=train)
summary(lm2)

pred1 <- predict(lm1, newdata=test)
corLR <- cor(pred1, test$Number_of_Casualties)
corLR
mse1 <- mean((pred1-test$Number_of_Casualties)^2)
mse1

             
pred2 <- predict(lm2, newdata=test)
corLR2 <- cor(pred2, test$Number_of_Casualties)
corLR2
mse2 <- mean((pred2-test$Number_of_Casualties)^2)
mse2


par(mfrow=c(2,2))
plot(lm1)
```

# kNN 

Next we will use kNN to perform regression on this dataset. When we use kNN to train and test on the the dataset, we end up getting a correlation of 0.626 and an mse of 2.028. This shows that kNN performed much better on our dataset than linear regression. 

```{r}
library(caret)

fit <- knnreg(train[,c(1:9,11:14)],train[,10],k=1)
predictions <- predict(fit, test[,c(1:9,11:14)])
cor_knn1 <- cor(predictions, test$Number_of_Casualties)
mse_knn1 <- mean((predictions - test$Number_of_Casualties)^2)
print(paste("cor of kNN=", cor_knn1))
print(paste("mse of kNN=", mse_knn1))


```

# Decision Trees

The final algorithm we will use will be Decision trees. When we use tree to train and test on the data, we end up with a correlation of 0.6817 and mse of 1.53. So far, this has been the best model as it has has the highest correlation and lowest mse. Now, lets try to prune the tree. 

```{r}
library(tree)
tree1 <- tree(Number_of_Casualties~., data=train)
summary(tree1)
predtree <- predict(tree1, newdata=test)
cortree <-  cor(predtree, test$Number_of_Casualties)
print(paste('correlation of tree:', cortree))
mse_tree <- mean((predtree-test$Number_of_Casualties)^2)
print(paste('mse of tree:', mse_tree))
plot(tree1)
text(tree1, cex=0.5, pretty=0)
```



```{r}
cv_tree <- cv.tree(tree1)
plot(cv_tree$size, cv_tree$dev, type='b')
```

It looks like it might be a good idea to prune the tree to 6 terminal nodes. When we do that, we get a correlation of 0.6178 and an mse of 1.7689. This is not as good as before. Hence, pruning did not improve the results of the data. 

```{r}
tree_pruned <- prune.tree(tree1, best=6)
plot(tree_pruned)
text(tree_pruned, pretty=0)

pred_pruned <- predict(tree_pruned, newdata=test)
cor_pruned <- cor(pred_pruned, test$Number_of_Casualties)
mse_pruned <- mean((pred_pruned-test$Number_of_Casualties)^2)

print(paste("correlation of pruned tree=", cor_pruned))
print(paste("mse of pruned tree=", mse_pruned))
```
# Results Analysis. 

Looking at all the metrics from the different algorithms, this is how I would rank the algorithms from best to worst:

1. Decision Trees 
2. kNN
3. Pruned Decision Tree
4. Linear Regression

Linear Regression performed pretty badly on the data and wasn't even able to get a correlation of 50%. This suggests that our data might not be linear and trying to fit into a linear model didn't work at all. kNN and Decisions trees did a pretty decent job at predicting the Number of Casualties by using the predictors provided. This suggests that our predictors are related to our target value in some form and predictions of the target value can be made using the predictors. That makes sense because when cleaning the data, I only kept predictors that seemed to be related to the target in some way.
Thus, this was a useful dataset.
